"""Tests for LLM plugin."""

import pytest
import respx
from httpx import Response

from meshgate.interfaces.node_context import NodeContext
from meshgate.plugins.llm_plugin import LLMPlugin


class TestLLMPlugin:
    """Tests for LLMPlugin class."""

    @pytest.fixture
    def plugin(self) -> LLMPlugin:
        """Create an LLMPlugin."""
        return LLMPlugin(
            ollama_url="http://localhost:11434",
            model="test-model",
            max_response_length=400,
            timeout=5.0,
        )

    def test_welcome_message(self, plugin: LLMPlugin) -> None:
        """Test welcome message shows model name."""
        welcome = plugin.get_welcome_message()
        assert "test-model" in welcome

    def test_help_text(self, plugin: LLMPlugin) -> None:
        """Test help text includes commands."""
        help_text = plugin.get_help_text()
        assert "!model" in help_text
        assert "!clear" in help_text
        assert "!exit" in help_text

    @pytest.mark.asyncio
    async def test_clear_command(self, plugin: LLMPlugin, context: NodeContext) -> None:
        """Test !clear clears history."""
        state = {"history": [{"role": "user", "content": "hi"}]}
        response = await plugin.handle("!clear", context, state)

        assert "cleared" in response.message.lower()
        assert response.plugin_state["history"] == []

    @pytest.mark.asyncio
    async def test_model_command_shows_current(
        self, plugin: LLMPlugin, context: NodeContext
    ) -> None:
        """Test !model shows the current configured model."""
        response = await plugin.handle("!model", context, {})

        assert "test-model" in response.message

    @pytest.mark.asyncio
    @respx.mock
    async def test_prompt_response(self, plugin: LLMPlugin, context: NodeContext) -> None:
        """Test sending a prompt and receiving response."""
        respx.post("http://localhost:11434/api/chat").mock(
            return_value=Response(
                200,
                json={
                    "message": {
                        "role": "assistant",
                        "content": "Test response from LLM",
                    }
                },
            )
        )

        response = await plugin.handle("Hello", context, {"history": []})

        assert "Test response from LLM" in response.message
        assert len(response.plugin_state["history"]) == 2

    @pytest.mark.asyncio
    @respx.mock
    async def test_response_truncation(self, plugin: LLMPlugin, context: NodeContext) -> None:
        """Test that long responses are truncated."""
        long_response = "x" * 500
        respx.post("http://localhost:11434/api/chat").mock(
            return_value=Response(
                200,
                json={
                    "message": {
                        "role": "assistant",
                        "content": long_response,
                    }
                },
            )
        )

        response = await plugin.handle("Hello", context, {"history": []})

        assert len(response.message) <= 400
        assert response.message.endswith("...")

    @pytest.mark.asyncio
    @respx.mock
    async def test_history_limited(self, plugin: LLMPlugin, context: NodeContext) -> None:
        """Test that history is limited in size."""
        respx.post("http://localhost:11434/api/chat").mock(
            return_value=Response(
                200,
                json={
                    "message": {
                        "role": "assistant",
                        "content": "Response",
                    }
                },
            )
        )

        # Start with long history
        long_history = [{"role": "user", "content": f"msg{i}"} for i in range(20)]
        response = await plugin.handle(
            "New message", context, {"history": long_history}
        )

        # History should be trimmed to the configured max
        assert len(response.plugin_state["history"]) <= LLMPlugin.MAX_HISTORY_MESSAGES
